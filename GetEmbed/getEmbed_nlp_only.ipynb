{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "import pprint\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BertConfig, BertLMHeadModel\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(n1, n2):\n",
    "    \"\"\"\n",
    "    takes 2 numpy array\n",
    "    n1, n2, each a vector embedding for a single code_string \n",
    "    \"\"\"\n",
    "    euclidean_dist=np.linalg.norm(n1-n2)\n",
    "    #print(n1==n2)\n",
    "    manhattan_dist=np.sum(np.abs(n1 - n2))\n",
    "    cosine_sim=np.dot(n1,n2)/(np.linalg.norm(n1)*np.linalg.norm(n2))\n",
    "    dot_product=np.dot(n1,n2)\n",
    "\n",
    "    return euclidean_dist, manhattan_dist, cosine_sim, dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edistances = []\n",
    "cosSims = []\n",
    "dotPros = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer.from_file('./tokenizer_nlp')\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "fast_tokenizer.mask_token='<mask>'\n",
    "fast_tokenizer.pad_token='<pad>'\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = BertLMHeadModel.from_pretrained('../saved_model/non_ast_transformer/checkpoint-12400/',output_hidden_states=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read scd-88 data\n",
    "with open('../saved_data/all.jsonl','r') as test_file:\n",
    "    test_list = list(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W,H=map(int,raw_input().strip().split(\" \"))\\n\\nif W*3 == H*4:\\n\\tprint \"4:3\"\\nelse:\\n\\tprint \"16:9\"\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(test_list[1*130])['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclids=list()\n",
    "cosines=list()\n",
    "dots=list()\n",
    "manhattans=list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i in range(0,88,1):\n",
    "        pairs=list()\n",
    "\n",
    "        p_euclid=list()\n",
    "        p_cosine=list()\n",
    "        p_dot=list()\n",
    "        p_manhattan=list()\n",
    "\n",
    "        for p in range(2,102,1):\n",
    "            clone1 = json.loads(test_list[i*130])['code']\n",
    "            clone2 = json.loads(test_list[i*130+p])['code']\n",
    "\n",
    "            pairs.append([clone1, clone2])\n",
    "\n",
    "            #print(clone1)\n",
    "            #print(clone2)\n",
    "            #print('---------')\n",
    "\n",
    "        # get embedding\n",
    "        for code_pair in pairs:\n",
    "            code1 = code_pair[0]\n",
    "            code2 = code_pair[1]\n",
    "        \n",
    "            # Tokenize the input sentence\n",
    "            id1 = fast_tokenizer.encode(code1, return_tensors='pt', max_length=512, truncation=True)\n",
    "            id2 = fast_tokenizer.encode(code2, return_tensors='pt', max_length=512, truncation=True)\n",
    "            #print(id1)\n",
    "            #print(type(id1))\n",
    "            #print(id1.shape)\n",
    "            out_clone1 = model(id1)\n",
    "            out_clone2 = model(id2)\n",
    "\n",
    "            v1=torch.zeros(out_clone1.hidden_states[0].shape)# v1, v2 must match the shape\n",
    "            v2=torch.zeros(out_clone2.hidden_states[0].shape)\n",
    "\n",
    "            for i in range(len(out_clone1.hidden_states)):# we have 3 layers\n",
    "                v1 += out_clone1.hidden_states[i]\n",
    "            \n",
    "            mean_embed_clone1 = torch.mean(v1, dim=1).squeeze()\n",
    "\n",
    "            for i in range(len(out_clone2.hidden_states)):# we have 3 layers\n",
    "                v2 += out_clone2.hidden_states[i]\n",
    "            \n",
    "            mean_embed_clone2 = torch.mean(v2, dim=1).squeeze()\n",
    "            #print(mean_embed_clone2.shape)\n",
    "\n",
    "            e,m,c,d = calculate_distance(mean_embed_clone1.numpy(), mean_embed_clone2.numpy())\n",
    "            \n",
    "            p_euclid.append(e)\n",
    "            p_cosine.append(c)\n",
    "            p_dot.append(d)\n",
    "            p_manhattan.append(m)\n",
    "\n",
    "        euclids.append(p_euclid)\n",
    "        cosines.append(p_cosine)\n",
    "        dots.append(p_dot)\n",
    "        manhattans.append(p_manhattan)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(euclids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('euclids_only_nlp.pkl', 'wb') as f:\n",
    "    pickle.dump(euclids, f)\n",
    "\n",
    "with open('cosine_only_nlp.pkl', 'wb') as f:\n",
    "    pickle.dump(cosines, f)\n",
    "\n",
    "with open('dot_only_nlp.pkl', 'wb') as f:\n",
    "    pickle.dump(dots, f)\n",
    "\n",
    "with open('manhattans_only_nlp.pkl', 'wb') as f:\n",
    "    pickle.dump(manhattans, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./euclids_only_nlp.pkl', 'rb') as f:\n",
    "#    l = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8432447,\n",
       " 5.644394,\n",
       " 3.6613176,\n",
       " 0.9989857,\n",
       " 1.9702805,\n",
       " 1.1753317,\n",
       " 4.8816905,\n",
       " 3.8191931,\n",
       " 2.370223,\n",
       " 1.3215207,\n",
       " 1.9702805,\n",
       " 2.4915447,\n",
       " 4.537694,\n",
       " 1.3256447,\n",
       " 1.4553967,\n",
       " 3.6063714,\n",
       " 4.4988256,\n",
       " 2.925626,\n",
       " 2.517416,\n",
       " 1.7358152,\n",
       " 2.0121646,\n",
       " 2.9400136,\n",
       " 1.4553967,\n",
       " 1.9702805,\n",
       " 0.9852411,\n",
       " 1.2771,\n",
       " 2.4687014,\n",
       " 2.1534142,\n",
       " 1.8908473,\n",
       " 2.1689742,\n",
       " 1.9702805,\n",
       " 1.3947265,\n",
       " 2.6271634,\n",
       " 1.3947265,\n",
       " 1.6337475,\n",
       " 2.2082965,\n",
       " 3.038416,\n",
       " 1.983991,\n",
       " 3.7895055,\n",
       " 2.7678428,\n",
       " 4.6914897,\n",
       " 1.4553967,\n",
       " 2.3895223,\n",
       " 2.1697364,\n",
       " 2.9980059,\n",
       " 4.0265017,\n",
       " 1.9702805,\n",
       " 2.925626,\n",
       " 1.8635972,\n",
       " 1.9702805,\n",
       " 1.0534362,\n",
       " 2.298209,\n",
       " 1.5221684,\n",
       " 2.6619682,\n",
       " 2.292061,\n",
       " 1.5770031,\n",
       " 2.82202,\n",
       " 2.331531,\n",
       " 0.5164221,\n",
       " 2.5341444,\n",
       " 1.7862774,\n",
       " 1.9749049,\n",
       " 2.058806,\n",
       " 2.2300646,\n",
       " 2.5235548,\n",
       " 2.341783,\n",
       " 2.7148845,\n",
       " 3.038416,\n",
       " 1.5522405,\n",
       " 1.2382998,\n",
       " 1.8432447,\n",
       " 1.7729185,\n",
       " 2.2015765,\n",
       " 1.9404409,\n",
       " 3.0917122,\n",
       " 2.1775548,\n",
       " 1.7566792,\n",
       " 1.2426649,\n",
       " 1.7214543,\n",
       " 2.3713617,\n",
       " 1.9649094,\n",
       " 3.282714,\n",
       " 1.3947265,\n",
       " 1.3947265,\n",
       " 1.3947265,\n",
       " 2.22705,\n",
       " 1.2336414,\n",
       " 1.8432447,\n",
       " 2.9435341,\n",
       " 1.3947265,\n",
       " 1.3215207,\n",
       " 3.0113993,\n",
       " 2.7399096,\n",
       " 1.9533151,\n",
       " 2.8615394,\n",
       " 1.3562206,\n",
       " 2.2016592,\n",
       " 2.1928787,\n",
       " 1.9622295,\n",
       " 2.0029438]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(euclids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
